import numpy as np
from .utils import custom_KDE, compute_mean, compute_mean_jac, TV_reg_1D
from .minimizers import funmin


def mll(m_list, inputs, pts=None, yy=None, accumulate=False):
    """Mean log loss as defined in (23) of Merchant and Ramos, ICRA 2014.

    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    pts : array_like
        Sampled points used for RMSE computation.
    yy : array_like
        Output values of the true map at `pts`.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the MLL for each model 
        in `m_list`. 

    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        mu, var = model.predict_noiseless(pts)
        mu, var, yy = mu.flatten(), var.flatten(), yy.flatten() 
        res[ii] = 0.5 * np.mean( np.log(2*np.pi*var) + (mu-yy)**2/var )

    if accumulate:
        res = np.minimum.accumulate(res)

    return res


def rmse(m_list, inputs, pts=None, yy=None, accumulate=False):
    """Root-mean-square error between GP model and objective function.

    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    pts : array_like
        Sampled points used for RMSE computation.
    yy : array_like
        Output values of the true map at `pts`.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the RMSE for each model 
        in `m_list`. 

    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        mu = model.predict(pts)[0]
        diff = mu.flatten() - yy.flatten()
        res[ii] = np.sqrt(np.mean(np.square(diff)))
    if accumulate:
        res = np.minimum.accumulate(res)
    return res
    

def log_pdf_log_pdf_diff_num(m_list, inputs, PDF_map=None, PDF_map_diff=None, mask1=None, mask2=None, 
                             y_vec_map=None, pts=None, binwidth=0.005, clip=True, accumulate=False):
    """Log-error between estimated pdf and true pdf.

    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    pt : instance of `FFTKDE` or dummy class
        The true pdf. If a dummy class is passed, it needs to have
        a method called `evaluate`. Dummy class is useful when the 
        true pdf has an analytical form and there is no need for KDE.
    pts : array_like
        Randomly sampled points used for KDE of the GP model.
    clip : boolean, optional
        Whether or not to clip the pdf values below machine-precision.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the log-error for each model 
        in `m_list`. The log-error is defined as
            e = \int | log(pdf_{GP}) - log(pdf_{true}) | dy 

    """

    res = np.zeros(len(m_list))
    
    pdf_diff_min_1 = np.nanmin(PDF_map_diff*mask1)
    pdf_diff_max_1 = np.nanmax(PDF_map_diff*mask1)
    
    pdf_diff_min_2 = np.nanmin(PDF_map_diff*mask2)
    pdf_diff_max_2 = np.nanmax(PDF_map_diff*mask2)

    for ii, model in enumerate(m_list):

        mu = model.predict(pts)[0].flatten()
        count_mu, bins_count_mu = np.histogram(mu, bins=int(np.max(mu)/binwidth))
        y_vec = np.linspace(np.max([y_vec_map[1],bins_count_mu[1]]),np.min([y_vec_map[-1], bins_count_mu[-1]]),1024)
        
        pdf_mu = count_mu / np.sum(count_mu)        
        pdf_model = np.interp(y_vec,bins_count_mu[1:],pdf_mu)
        
        pdf_model_smooth_log = TV_reg_1D(np.log(pdf_model))
        
        PDF_model_diff = np.gradient(pdf_model_smooth_log, y_vec)
        
        model_pdf_diff_min_1 = np.nanmin(PDF_model_diff*mask1)
        model_pdf_diff_max_1 = np.nanmax(PDF_model_diff*mask1)
        
        model_pdf_diff_min_2 = np.nanmin(PDF_model_diff*mask2)
        model_pdf_diff_max_2 = np.nanmax(PDF_model_diff*mask2)
        
        # pdf_map = np.interp(y_vec,y_vec_map[1:],PDF_map)
        pdf_map = PDF_map
        
        log_yb, log_yt = np.log(pdf_model), np.log(pdf_map)

        if clip: # Clip to machine-precision
            np.clip(log_yb, -14, None, out=log_yb)
            np.clip(log_yt, -14, None, out=log_yt)

        log_diff = np.abs(log_yb-log_yt)
        noInf = np.isfinite(log_diff)
        res[ii] = np.trapz(log_diff[noInf], y_vec[noInf]) + np.abs(pdf_diff_min_1 - model_pdf_diff_min_1) + np.abs(pdf_diff_max_1 - model_pdf_diff_max_1) + np.abs(pdf_diff_min_2 - model_pdf_diff_min_2) + np.abs(pdf_diff_max_2 - model_pdf_diff_max_2)

    if accumulate:
        res = np.minimum.accumulate(res)

    return res


def log_pdf_num(m_list, inputs, PDF_map=None, y_vec_map=None, pts=None, binwidth=0.005, clip=True, 
            accumulate=False):
    """Log-error between estimated pdf and true pdf.

    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    pt : instance of `FFTKDE` or dummy class
        The true pdf. If a dummy class is passed, it needs to have
        a method called `evaluate`. Dummy class is useful when the 
        true pdf has an analytical form and there is no need for KDE.
    pts : array_like
        Randomly sampled points used for KDE of the GP model.
    clip : boolean, optional
        Whether or not to clip the pdf values below machine-precision.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the log-error for each model 
        in `m_list`. The log-error is defined as
            e = \int | log(pdf_{GP}) - log(pdf_{true}) | dy 

    """

    res = np.zeros(len(m_list))

    for ii, model in enumerate(m_list):

        mu = model.predict(pts)[0].flatten()
        count_mu, bins_count_mu = np.histogram(mu, bins=int(np.max(mu)/binwidth))
        y_vec = np.linspace(np.max([y_vec_map[1],bins_count_mu[1]]),np.min([y_vec_map[-1], bins_count_mu[-1]]),len(y_vec_map))
        
        pdf_mu = count_mu / np.sum(count_mu)        
        pdf_model = np.interp(y_vec,bins_count_mu[1:],pdf_mu)
        # print('bins_count_mu len is ',len(bins_count_mu[1:]))
        # print('pdf_mu len is ',len(pdf_mu))
        
        pdf_map = np.interp(y_vec,y_vec_map,PDF_map)
        # print('y_vec_map len is ',len(y_vec_map[1:]))
        # print('pdf_map len is ',len(pdf_map))
        
        log_yb, log_yt = np.log(pdf_model), np.log(pdf_map)

        if clip: # Clip to machine-precision
            np.clip(log_yb, -14, None, out=log_yb)
            np.clip(log_yt, -14, None, out=log_yt)

        log_diff = np.abs(log_yb-log_yt)
        noInf = np.isfinite(log_diff)
        res[ii] = np.trapz(log_diff[noInf], y_vec[noInf])

    if accumulate:
        res = np.minimum.accumulate(res)

    return res


def log_pdf(m_list, inputs, pt=None, pts=None, clip=True, 
            accumulate=False):
    """Log-error between estimated pdf and true pdf.

    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    pt : instance of `FFTKDE` or dummy class
        The true pdf. If a dummy class is passed, it needs to have
        a method called `evaluate`. Dummy class is useful when the 
        true pdf has an analytical form and there is no need for KDE.
    pts : array_like
        Randomly sampled points used for KDE of the GP model.
    clip : boolean, optional
        Whether or not to clip the pdf values below machine-precision.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the log-error for each model 
        in `m_list`. The log-error is defined as
            e = \int | log(pdf_{GP}) - log(pdf_{true}) | dy 

    """

    res = np.zeros(len(m_list))

    for ii, model in enumerate(m_list):

        mu = model.predict(pts)[0].flatten()
        ww = inputs.pdf(pts)
        pb = custom_KDE(mu, weights=ww, bw=.05)

        x_min = min( pb.data.min(), pt.data.min() )
        x_max = max( pb.data.max(), pt.data.max() )
        rang = x_max-x_min
        x_eva = np.linspace(x_min - 0.01*rang,
                            x_max + 0.01*rang, 1024)

        yb, yt = pb.evaluate(x_eva), pt.evaluate(x_eva)
        log_yb, log_yt = np.log(yb), np.log(yt)
        log_yb = log_yb[(x_eva<3) * (x_eva>-3)]
        log_yt = log_yt[(x_eva<3) * (x_eva>-3)]

        if clip: # Clip to machine-precision
            np.clip(log_yb, -14, None, out=log_yb)
            np.clip(log_yt, -14, None, out=log_yt)

        log_diff = np.abs(log_yb-log_yt)
        # noInf = np.isfinite(log_diff)
        # res[ii] = np.trapz(log_diff[noInf], x_eva[noInf])
        res[ii] = np.trapz(log_diff, x_eva[(x_eva<3) * (x_eva>-3)])
        np.trapz(log_diff, x_eva[(x_eva<3) * (x_eva>-3)])

    if accumulate:
        res = np.minimum.accumulate(res)

    return res


def regret_tmap(m_list, inputs, true_ymin=0, tmap=None, 
                accumulate=False):
    """Immediate regret using objective function.

    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    true_ymin : float, optional
        The minimum value of the objective function.
    tmap : instance of `BlackBox`
        The black box.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the immediate regret for each 
        model in `m_list` using the black-box objective function:
            $r(n) = f(x_n) - y_{true}$
        where f is the black box, x_n the algorithm recommendation at 
        iteration n, and y_{true} the minimum of the objective function.

    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        x_min = recommend(model, inputs)
        y_min = tmap.evaluate(x_min, include_noise=False)
        res[ii] = y_min - true_ymin
    if accumulate:
        res = np.minimum.accumulate(res)
    return res


def regret_model(m_list, inputs, true_ymin=0, accumulate=False):
    """Immediate regret using surrogate GP model.
    
    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    true_ymin : float, optional
        The minimum value of the objective function.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the immediate regret for each 
        model in `m_list` using the surrogate GP model:
            $r(n) = \hat{f}_n(x_n) - y_{true}$
        where \hat{f}_n is the GP model at iteration n, x_n the 
        algorithm recommendation at iteration n, and y_{true} the 
        minimum of the objective function.

    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        x_min = recommend(model, inputs)
        y_min = compute_mean(x_min, model)
        res[ii] = np.abs(y_min - true_ymin)
    if accumulate:
        res = np.minimum.accumulate(res)
    return res


def regret_obs(m_list, inputs, true_ymin=0):
    """Immediate regret using past observations.
    
    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    true_ymin : float, optional
        The minimum value of the objective function.
       
    Returns
    -------
    res : list
        A list containing the values of the immediate regret for each 
        model in `m_list` using past observations:
            $r(n) = min y_i - y_{true}$
        where y_i are the observations recorded in the first `n` 
        iterations, and y_{true} the minimum of the objective function. 

    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        res[ii] = model.Y.min() - true_ymin
    return res


def distmin_model(m_list, inputs, true_xmin=[], accumulate=False):
    """Distance to minimum using surrogate GP model.
    
    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    true_xmin : array_like or list
        The locations of the minima of the objective function.
    accumulate : boolean, optional
        Whether or not to report the running minimum of the metric.
       
    Returns
    -------
    res : list
        A list containing the values of the distance to minimum for each 
        model in `m_list` using the surrogate GP model:
            $\ell(n) = \Vert x_n - x_{true} \Vert^2$
        where x_n is the algorithm recommendation at iteration n, and 
        x_{true} the location of the minimum of the objective function.
        When more than one global minimum exists, we compute the 
        distance to each minimum and report the smallest value.
    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        x_min = recommend(model, inputs)
        l2_dist = [ np.linalg.norm(x_min - true) for true in true_xmin ]
        res[ii] = min(l2_dist)
    if accumulate:
        res = np.minimum.accumulate(res)
    return res


def distmin_obs(m_list, inputs, true_xmin=[]):
    """Distance to minimum using past observations.
    
    Parameters
    ----------
    m_list : list
        A list of GPy models generated by `OptimalDesign`.
    inputs : instance of `Inputs`
        The input space.
    true_xmin : array_like or list
        The locations of the minima of the objective function.
       
    Returns
    -------
    res : list
        A list containing the values of the distance to minimum for each 
        model in `m_list` using past observations:
            $\ell(n) = \Vert argmin x_i - x_{true} \Vert^2$
        where x_i is the location of the current best observation,
        and x_{true} the location of the minimum of the objective 
        function. When more than one global minimizer exists, we 
        compute the distance to each minimizer and report the smallest 
        value.
    """
    res = np.zeros(len(m_list))
    for ii, model in enumerate(m_list):
        x_min = model.X[np.argmin(model.Y)]
        l2_dist = [ np.linalg.norm(x_min - true) for true in true_xmin ]
        res[ii] = min(l2_dist)
    return res


def recommend(model, inputs, num_restarts=10, parallel_restarts=False):
    """Compute recommendation for where minimum is located.
    
    Parameters
    ----------
    model : instance of `GPRegression`
        A GPy model.
    inputs : instance of `Inputs`
        The input space.
    num_restarts : int, optional
        Number of restarts for the optimizer. 
    parallel_restarts : boolean, optional
        Whether or not to solve the optimization problems in parallel.
       
    Returns
    -------
    x_min : array
        The recommendation for where the GP model believes the global 
        minimum is located.
    """
    if parallel_restarts:
        set_worker_env()
    x_min = funmin(compute_mean,
                   compute_mean_jac,
                   inputs,
                   args=(model,),
                   num_restarts=num_restarts,
                   parallel_restarts=parallel_restarts,
                   init_method="sample_fun")
    return x_min




# %%
# import numpy as np
# from .utils import custom_KDE, compute_mean, compute_mean_jac
# from .minimizers import funmin


# def mll(m_list, inputs, pts=None, yy=None, accumulate=False):
#     """Mean log loss as defined in (23) of Merchant and Ramos, ICRA 2014.

#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     pts : array_like
#         Sampled points used for RMSE computation.
#     yy : array_like
#         Output values of the true map at `pts`.
#     accumulate : boolean, optional
#         Whether or not to report the running minimum of the metric.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the MLL for each model 
#         in `m_list`. 

#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         mu, var = model.predict_noiseless(pts)
#         mu, var, yy = mu.flatten(), var.flatten(), yy.flatten() 
#         res[ii] = 0.5 * np.mean( np.log(2*np.pi*var) + (mu-yy)**2/var )

#     if accumulate:
#         res = np.minimum.accumulate(res)

#     return res


# def rmse(m_list, inputs, pts=None, yy=None, accumulate=False):
#     """Root-mean-square error between GP model and objective function.

#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     pts : array_like
#         Sampled points used for RMSE computation.
#     yy : array_like
#         Output values of the true map at `pts`.
#     accumulate : boolean, optional
#         Whether or not to report the running minimum of the metric.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the RMSE for each model 
#         in `m_list`. 

#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         mu = model.predict(pts)[0]
#         diff = mu.flatten() - yy.flatten()
#         res[ii] = np.sqrt(np.mean(np.square(diff)))
#     if accumulate:
#         res = np.minimum.accumulate(res)
#     return res
    

# def log_pdf(m_list, inputs, pt=None, pts=None, clip=True, 
#             accumulate=False):
#     """Log-error between estimated pdf and true pdf.

#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     pt : instance of `FFTKDE` or dummy class
#         The true pdf. If a dummy class is passed, it needs to have
#         a method called `evaluate`. Dummy class is useful when the 
#         true pdf has an analytical form and there is no need for KDE.
#     pts : array_like
#         Randomly sampled points used for KDE of the GP model.
#     clip : boolean, optional
#         Whether or not to clip the pdf values below machine-precision.
#     accumulate : boolean, optional
#         Whether or not to report the running minimum of the metric.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the log-error for each model 
#         in `m_list`. The log-error is defined as
#             e = \int | log(pdf_{GP}) - log(pdf_{true}) | dy 

#     """

#     res = np.zeros(len(m_list))

#     for ii, model in enumerate(m_list):

#         mu = model.predict(pts)[0].flatten()
#         ww = inputs.pdf(pts)
#         pb = custom_KDE(mu, weights=ww)

#         x_min = min( pb.data.min(), pt.data.min() )
#         x_max = max( pb.data.max(), pt.data.max() )
#         rang = x_max-x_min
#         x_eva = np.linspace(x_min - 0.01*rang,
#                             x_max + 0.01*rang, 1024)

#         yb, yt = pb.evaluate(x_eva), pt.evaluate(x_eva)
#         log_yb, log_yt = np.log(yb), np.log(yt)

#         if clip: # Clip to machine-precision
#             np.clip(log_yb, -14, None, out=log_yb)
#             np.clip(log_yt, -14, None, out=log_yt)

#         log_diff = np.abs(log_yb-log_yt)
#         noInf = np.isfinite(log_diff)
#         res[ii] = np.trapz(log_diff[noInf], x_eva[noInf])

#     if accumulate:
#         res = np.minimum.accumulate(res)

#     return res


# def regret_tmap(m_list, inputs, true_ymin=0, tmap=None, 
#                 accumulate=False):
#     """Immediate regret using objective function.

#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     true_ymin : float, optional
#         The minimum value of the objective function.
#     tmap : instance of `BlackBox`
#         The black box.
#     accumulate : boolean, optional
#         Whether or not to report the running minimum of the metric.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the immediate regret for each 
#         model in `m_list` using the black-box objective function:
#             $r(n) = f(x_n) - y_{true}$
#         where f is the black box, x_n the algorithm recommendation at 
#         iteration n, and y_{true} the minimum of the objective function.

#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         x_min = recommend(model, inputs)
#         y_min = tmap.evaluate(x_min, include_noise=False)
#         res[ii] = y_min - true_ymin
#     if accumulate:
#         res = np.minimum.accumulate(res)
#     return res


# def regret_model(m_list, inputs, true_ymin=0, accumulate=False):
#     """Immediate regret using surrogate GP model.
    
#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     true_ymin : float, optional
#         The minimum value of the objective function.
#     accumulate : boolean, optional
#         Whether or not to report the running minimum of the metric.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the immediate regret for each 
#         model in `m_list` using the surrogate GP model:
#             $r(n) = \hat{f}_n(x_n) - y_{true}$
#         where \hat{f}_n is the GP model at iteration n, x_n the 
#         algorithm recommendation at iteration n, and y_{true} the 
#         minimum of the objective function.

#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         x_min = recommend(model, inputs)
#         y_min = compute_mean(x_min, model)
#         res[ii] = np.abs(y_min - true_ymin)
#     if accumulate:
#         res = np.minimum.accumulate(res)
#     return res


# def regret_obs(m_list, inputs, true_ymin=0):
#     """Immediate regret using past observations.
    
#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     true_ymin : float, optional
#         The minimum value of the objective function.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the immediate regret for each 
#         model in `m_list` using past observations:
#             $r(n) = min y_i - y_{true}$
#         where y_i are the observations recorded in the first `n` 
#         iterations, and y_{true} the minimum of the objective function. 

#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         res[ii] = model.Y.min() - true_ymin
#     return res


# def distmin_model(m_list, inputs, true_xmin=[], accumulate=False):
#     """Distance to minimum using surrogate GP model.
    
#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     true_xmin : array_like or list
#         The locations of the minima of the objective function.
#     accumulate : boolean, optional
#         Whether or not to report the running minimum of the metric.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the distance to minimum for each 
#         model in `m_list` using the surrogate GP model:
#             $\ell(n) = \Vert x_n - x_{true} \Vert^2$
#         where x_n is the algorithm recommendation at iteration n, and 
#         x_{true} the location of the minimum of the objective function.
#         When more than one global minimum exists, we compute the 
#         distance to each minimum and report the smallest value.
#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         x_min = recommend(model, inputs)
#         l2_dist = [ np.linalg.norm(x_min - true) for true in true_xmin ]
#         res[ii] = min(l2_dist)
#     if accumulate:
#         res = np.minimum.accumulate(res)
#     return res


# def distmin_obs(m_list, inputs, true_xmin=[]):
#     """Distance to minimum using past observations.
    
#     Parameters
#     ----------
#     m_list : list
#         A list of GPy models generated by `OptimalDesign`.
#     inputs : instance of `Inputs`
#         The input space.
#     true_xmin : array_like or list
#         The locations of the minima of the objective function.
       
#     Returns
#     -------
#     res : list
#         A list containing the values of the distance to minimum for each 
#         model in `m_list` using past observations:
#             $\ell(n) = \Vert argmin x_i - x_{true} \Vert^2$
#         where x_i is the location of the current best observation,
#         and x_{true} the location of the minimum of the objective 
#         function. When more than one global minimizer exists, we 
#         compute the distance to each minimizer and report the smallest 
#         value.
#     """
#     res = np.zeros(len(m_list))
#     for ii, model in enumerate(m_list):
#         x_min = model.X[np.argmin(model.Y)]
#         l2_dist = [ np.linalg.norm(x_min - true) for true in true_xmin ]
#         res[ii] = min(l2_dist)
#     return res


# def recommend(model, inputs, num_restarts=10, parallel_restarts=False):
#     """Compute recommendation for where minimum is located.
    
#     Parameters
#     ----------
#     model : instance of `GPRegression`
#         A GPy model.
#     inputs : instance of `Inputs`
#         The input space.
#     num_restarts : int, optional
#         Number of restarts for the optimizer. 
#     parallel_restarts : boolean, optional
#         Whether or not to solve the optimization problems in parallel.
       
#     Returns
#     -------
#     x_min : array
#         The recommendation for where the GP model believes the global 
#         minimum is located.
#     """
#     if parallel_restarts:
#         set_worker_env()
#     x_min = funmin(compute_mean,
#                    compute_mean_jac,
#                    inputs,
#                    args=(model,),
#                    num_restarts=num_restarts,
#                    parallel_restarts=parallel_restarts,
#                    init_method="sample_fun")
#     return x_min



